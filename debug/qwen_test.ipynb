{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "from modeling_llama import LlamaForCausalLM\n",
    "from modeling_qwen2 import Qwen2ForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "Sliding Window Attention is enabled but not implemented for `eager`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "qwen = Qwen2ForCausalLM.from_pretrained('Qwen/Qwen2.5-0.5B-Instruct', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama = LlamaForCausalLM.from_pretrained('TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen2.5-0.5B-Instruct', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_tokenizer = AutoTokenizer.from_pretrained('TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'hello, i want to ask a question.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_out(tokenizer, model):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=None, logits=tensor([[[ 6.0533,  7.4447,  1.8474,  ..., -3.6125, -3.6126, -3.6124],\n",
       "         [ 7.2889,  0.5593,  1.7174,  ..., -1.6823, -1.6826, -1.6823],\n",
       "         [ 7.3283, 11.6468,  6.2543,  ..., -0.6932, -0.6931, -0.6933],\n",
       "         ...,\n",
       "         [ 4.5095,  7.1071,  1.9765,  ..., -1.5999, -1.6002, -1.5998],\n",
       "         [12.9693,  8.6220,  7.5914,  ..., -1.3806, -1.3811, -1.3806],\n",
       "         [ 4.2194, -2.8747,  2.2909,  ..., -1.3105, -1.3107, -1.3105]]]), past_key_values=DynamicCache(), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_out(qwen_tokenizer, qwen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=None, logits=tensor([[[ -1.7340,   1.9886,   2.8448,  ...,  -5.0302,  -0.5283,  -3.0332],\n",
       "         [-10.5965, -10.5071,   4.6207,  ...,  -3.6732,  -8.2869,  -2.3295],\n",
       "         [-11.3276, -11.3347,   3.4832,  ...,  -3.9248,  -8.1235,  -3.3417],\n",
       "         ...,\n",
       "         [-10.1122, -10.0458,   2.2868,  ...,  -4.8756,  -5.5799,  -4.8860],\n",
       "         [-10.4501, -10.3186,   4.9481,  ...,  -3.1721,  -6.3883,  -1.7319],\n",
       "         [-11.2099, -11.0803,   6.6967,  ...,  -4.4150,  -8.4510,  -2.8751]]]), past_key_values=DynamicCache(), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_out(llama_tokenizer, llama)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
